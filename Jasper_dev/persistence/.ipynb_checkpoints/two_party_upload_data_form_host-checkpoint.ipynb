{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hetero_two_party_continual_input_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx        0\n",
      "ambient    0\n",
      "coolant    0\n",
      "u_d        0\n",
      "u_q        0\n",
      "torque     0\n",
      "i_d        0\n",
      "i_q        0\n",
      "dtype: int64\n",
      "   idx   ambient   coolant       u_d       u_q    torque       i_d       i_q\n",
      "0    1  0.047104 -0.555098  0.444256  1.704733 -0.342206  0.994721 -0.349791\n",
      "1    2  0.671626  0.350670  0.319092 -1.327874 -0.255640  1.029143 -0.245723\n",
      "2    3 -0.552205  1.989043 -0.084323 -0.775999  1.311668  0.147598  1.442962\n",
      "3    4  0.683789 -0.106609  0.181350  1.717412 -0.249906 -0.362698 -0.242594\n",
      "4    5 -0.007996  0.379668  2.172504 -0.297852 -2.149669 -1.180890 -2.030358\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"motor_hetero_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/motor_hetero_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上傳資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-12 05:46:48.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306120546479409490\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:48.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0mm2023-06-12 05:46:49.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-12 05:46:49.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:50.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:51.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:52.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:53.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:54.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:55.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:56.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:57.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306120546479409490\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:57.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:09\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hetero_two_party_continual_input_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id     0\n",
      "x0     0\n",
      "x1     0\n",
      "x2     0\n",
      "x3     0\n",
      "x4     0\n",
      "x5     0\n",
      "x6     0\n",
      "x7     0\n",
      "x8     0\n",
      "x9     0\n",
      "x10    0\n",
      "x11    0\n",
      "x12    0\n",
      "x13    0\n",
      "x14    0\n",
      "x15    0\n",
      "x16    0\n",
      "x17    0\n",
      "x18    0\n",
      "x19    0\n",
      "dtype: int64\n",
      "    id        x0        x1        x2        x3        x4        x5        x6  \\\n",
      "0  133  0.449512 -1.247226  0.413178  0.303781 -0.123848 -0.184227 -0.219076   \n",
      "1  273 -1.245485 -0.842317 -1.255026 -1.038066 -0.426301 -1.088781 -0.976392   \n",
      "2  175 -1.549664 -1.126219 -1.546652 -1.216392 -0.354424 -1.167051 -1.114873   \n",
      "3  551 -0.851273  0.733108 -0.843535 -0.786363 -0.049836 -0.424532 -0.509221   \n",
      "4  199  0.091654  0.216499  0.103839 -0.034667  0.167930  0.308132  0.366614   \n",
      "\n",
      "         x7        x8  ...       x10       x11       x12       x13       x14  \\\n",
      "0  0.268537  0.015996  ... -0.337360 -0.728193 -0.442587 -0.272757 -0.608018   \n",
      "1 -0.898898  0.983496  ... -0.493639  0.348620 -0.552483 -0.526877  2.253098   \n",
      "2 -1.261820 -0.327193  ... -0.666881 -0.779358 -0.708418 -0.637545  0.710369   \n",
      "3 -0.679649  0.797298  ... -0.451772  0.453852 -0.431696 -0.494754 -1.182041   \n",
      "4  0.280661  0.505223  ... -0.707304 -1.026834 -0.702973 -0.460212 -0.999033   \n",
      "\n",
      "        x15       x16       x17       x18       x19  \n",
      "0 -0.577235 -0.501126  0.143371 -0.466431 -0.554102  \n",
      "1 -0.827620 -0.780739 -0.376997 -0.310239  0.176301  \n",
      "2 -0.976454 -1.057501 -1.913447  0.795207 -0.149751  \n",
      "3  0.281228  0.084759 -0.252420  1.038575  0.351054  \n",
      "4 -0.531406 -0.394360 -0.728830 -0.644416 -0.688003  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"breast_hetero_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/breast_hetero_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上傳資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/projects/python/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-06 05:34:05.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306060534058190480\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:05.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-06 05:34:06.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2023-06-06 05:34:08.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-06 05:34:08.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:09.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:10.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:11.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:12.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:13.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:14.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:15.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:16.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306060534058190480\u001b[0m\n",
      "\u001b[32m2023-06-06 05:34:16.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hetero_two_party_hybrid_input_classification\n",
    "\n",
    "#### embarked 欄位有缺值 Data Transform 時要設定補缺值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passengerid    0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       2\n",
      "dtype: int64\n",
      "   passengerid  parch     fare embarked\n",
      "0            1      0   7.2500        S\n",
      "1            2      0  71.2833        C\n",
      "2            3      0   7.9250        S\n",
      "3            4      0  53.1000        S\n",
      "4            5      0   8.0500        S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"titanic_hetero_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/titanic_hetero_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))\n",
    "dense_df.embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上傳資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-06 05:43:00.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306060543003934990\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:00.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0mm2023-06-06 05:43:01.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-06 05:43:01.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:02.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:03.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:04.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:05.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:06.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:07.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:08.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:09.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306060543003934990\u001b[0m\n",
      "\u001b[32m2023-06-06 05:43:09.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:09\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# homo_two_party_continual_input_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id     0\n",
      "y      0\n",
      "x0     0\n",
      "x1     0\n",
      "x2     0\n",
      "x3     0\n",
      "x4     0\n",
      "x5     0\n",
      "x6     0\n",
      "x7     0\n",
      "x8     0\n",
      "x9     0\n",
      "x10    0\n",
      "x11    0\n",
      "x12    0\n",
      "x13    0\n",
      "x14    0\n",
      "x15    0\n",
      "x16    0\n",
      "x17    0\n",
      "x18    0\n",
      "x19    0\n",
      "x20    0\n",
      "x21    0\n",
      "x22    0\n",
      "x23    0\n",
      "x24    0\n",
      "x25    0\n",
      "x26    0\n",
      "x27    0\n",
      "x28    0\n",
      "x29    0\n",
      "dtype: int64\n",
      "    id  y        x0        x1        x2        x3        x4        x5  \\\n",
      "0  565  0  1.536720  2.047399  1.421940  1.494959 -0.691230 -0.394820   \n",
      "1  447  1  0.033301 -0.478309 -0.040545 -0.089800 -0.428215 -0.420902   \n",
      "2  488  1 -0.610726 -0.665579 -0.616305 -0.581488  0.886862 -0.677903   \n",
      "3  151  1 -1.486271  0.658341 -1.464904 -1.108862  1.342755  1.124281   \n",
      "4  263  0  0.339783  0.975886  0.257314  0.189884 -1.050685 -0.467976   \n",
      "\n",
      "         x6        x7  ...       x20       x21       x22       x23       x24  \\\n",
      "0  0.236573  0.733827  ...  1.300499  2.260938  1.156857  1.291565 -0.424010   \n",
      "1 -0.317541 -0.480037  ... -0.666881 -1.079087 -0.685152 -0.452951 -0.748357   \n",
      "2 -0.591000 -0.250572  ... -0.122251 -0.114038 -0.154479 -0.280898  0.652367   \n",
      "3  1.275717 -0.545359  ... -0.763969  1.351952 -0.803464 -0.662847  1.796413   \n",
      "4 -0.221590 -0.440448  ... -0.632955 -0.395624 -0.659410 -0.399487 -1.405050   \n",
      "\n",
      "        x25       x26       x27       x28       x29  \n",
      "0 -0.069758  0.252202  0.808431 -0.189161 -0.490556  \n",
      "1 -0.769495 -0.474600 -0.794687  0.241879 -0.689894  \n",
      "2 -0.701869 -0.443764 -0.020461  0.118379 -0.220106  \n",
      "3  1.603016  1.513163 -0.255665  0.308472  3.020373  \n",
      "4 -0.915087 -0.622812 -1.074175 -1.260706 -0.926679  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"breast_homo_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/breast_homo_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-12 05:46:34.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306120546344418240\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:34.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0mm2023-06-12 05:46:35.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-12 05:46:35.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:36.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:37.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:38.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:39.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:40.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:41.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:42.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:43.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:44.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306120546344418240\u001b[0m\n",
      "\u001b[32m2023-06-12 05:46:44.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad4309918fa4cd1705b305e369b2f64d901b1851e9144aef7b9b07ea3efcb1bb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
