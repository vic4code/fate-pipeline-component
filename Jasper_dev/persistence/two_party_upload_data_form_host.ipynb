{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hetero_two_party_continual_input_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx        0\n",
      "ambient    0\n",
      "coolant    0\n",
      "u_d        0\n",
      "u_q        0\n",
      "torque     0\n",
      "i_d        0\n",
      "i_q        0\n",
      "dtype: int64\n",
      "   idx   ambient   coolant       u_d       u_q    torque       i_d       i_q\n",
      "0    1  0.047104 -0.555098  0.444256  1.704733 -0.342206  0.994721 -0.349791\n",
      "1    2  0.671626  0.350670  0.319092 -1.327874 -0.255640  1.029143 -0.245723\n",
      "2    3 -0.552205  1.989043 -0.084323 -0.775999  1.311668  0.147598  1.442962\n",
      "3    4  0.683789 -0.106609  0.181350  1.717412 -0.249906 -0.362698 -0.242594\n",
      "4    5 -0.007996  0.379668  2.172504 -0.297852 -2.149669 -1.180890 -2.030358\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"motor_hetero_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/motor_hetero_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/projects/python/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:14.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306130555143996660\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:14.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0mm2023-06-13 05:55:15.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-13 05:55:15.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:16.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:17.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:18.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:19.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:20.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:21.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:22.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:23.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:24.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306130555143996660\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:24.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hetero_two_party_continual_input_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id     0\n",
      "x0     0\n",
      "x1     0\n",
      "x2     0\n",
      "x3     0\n",
      "x4     0\n",
      "x5     0\n",
      "x6     0\n",
      "x7     0\n",
      "x8     0\n",
      "x9     0\n",
      "x10    0\n",
      "x11    0\n",
      "x12    0\n",
      "x13    0\n",
      "x14    0\n",
      "x15    0\n",
      "x16    0\n",
      "x17    0\n",
      "x18    0\n",
      "x19    0\n",
      "dtype: int64\n",
      "    id        x0        x1        x2        x3        x4        x5        x6  \\\n",
      "0  133  0.449512 -1.247226  0.413178  0.303781 -0.123848 -0.184227 -0.219076   \n",
      "1  273 -1.245485 -0.842317 -1.255026 -1.038066 -0.426301 -1.088781 -0.976392   \n",
      "2  175 -1.549664 -1.126219 -1.546652 -1.216392 -0.354424 -1.167051 -1.114873   \n",
      "3  551 -0.851273  0.733108 -0.843535 -0.786363 -0.049836 -0.424532 -0.509221   \n",
      "4  199  0.091654  0.216499  0.103839 -0.034667  0.167930  0.308132  0.366614   \n",
      "\n",
      "         x7        x8  ...       x10       x11       x12       x13       x14  \\\n",
      "0  0.268537  0.015996  ... -0.337360 -0.728193 -0.442587 -0.272757 -0.608018   \n",
      "1 -0.898898  0.983496  ... -0.493639  0.348620 -0.552483 -0.526877  2.253098   \n",
      "2 -1.261820 -0.327193  ... -0.666881 -0.779358 -0.708418 -0.637545  0.710369   \n",
      "3 -0.679649  0.797298  ... -0.451772  0.453852 -0.431696 -0.494754 -1.182041   \n",
      "4  0.280661  0.505223  ... -0.707304 -1.026834 -0.702973 -0.460212 -0.999033   \n",
      "\n",
      "        x15       x16       x17       x18       x19  \n",
      "0 -0.577235 -0.501126  0.143371 -0.466431 -0.554102  \n",
      "1 -0.827620 -0.780739 -0.376997 -0.310239  0.176301  \n",
      "2 -0.976454 -1.057501 -1.913447  0.795207 -0.149751  \n",
      "3  0.281228  0.084759 -0.252420  1.038575  0.351054  \n",
      "4 -0.531406 -0.394360 -0.728830 -0.644416 -0.688003  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"breast_hetero_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/breast_hetero_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:24.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306130555247543930\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:24.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:25.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2023-06-13 05:55:26.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-13 05:55:26.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:27.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:28.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:29.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:31.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:32.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:33.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:34.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:35.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306130555247543930\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:35.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hetero_two_party_hybrid_input_classification\n",
    "\n",
    "#### embarked 欄位有缺值 Data Transform 時要設定補缺值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passengerid    0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       2\n",
      "dtype: int64\n",
      "   passengerid  parch     fare embarked\n",
      "0            1      0   7.2500        S\n",
      "1            2      0  71.2833        C\n",
      "2            3      0   7.9250        S\n",
      "3            4      0  53.1000        S\n",
      "4            5      0   8.0500        S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"titanic_hetero_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/titanic_hetero_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))\n",
    "dense_df.embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:35.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306130555350962100\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:35.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:36.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2023-06-13 05:55:37.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-13 05:55:37.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:38.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:39.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:40.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:41.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:42.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:43.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:44.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:45.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306130555350962100\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:45.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homogeneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## homo_two_party_continual_input_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx               0\n",
      "motor_speed       0\n",
      "pm                0\n",
      "stator_yoke       0\n",
      "stator_tooth      0\n",
      "stator_winding    0\n",
      "ambient           0\n",
      "coolant           0\n",
      "u_d               0\n",
      "u_q               0\n",
      "torque            0\n",
      "i_d               0\n",
      "i_q               0\n",
      "dtype: int64\n",
      "   idx  motor_speed        pm  stator_yoke  stator_tooth  stator_winding  \\\n",
      "0  101     0.164041 -0.009123     0.236624      0.343391        0.434495   \n",
      "1  102    -0.684048 -1.394136    -0.765215     -0.383516        0.332318   \n",
      "2  103    -0.161892 -1.586367    -1.442825     -1.534831       -1.549754   \n",
      "3  104    -0.534374 -0.145709     0.257089      0.155786        0.143559   \n",
      "4  105    -0.151495  0.732172     1.419455      0.998102        0.515637   \n",
      "\n",
      "    ambient   coolant       u_d       u_q    torque       i_d       i_q  \n",
      "0  0.008540  0.070099 -1.344984  0.238741  1.207354 -0.659899  1.176607  \n",
      "1 -1.443360 -1.069117 -0.752379 -0.597510  2.460529 -0.981011  2.408498  \n",
      "2 -2.470108 -1.067210 -0.345828  0.837823  0.326439  0.850139  0.417108  \n",
      "3  0.467122  0.316744 -0.726652 -0.171278  1.481841  0.005629  1.604845  \n",
      "4  0.688609  1.747516  0.947338  0.657549 -0.823026  0.873803 -0.907745  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"motor_homo_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/motor_homo_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:45.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306130555454426000\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:45.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:46.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2023-06-13 05:55:47.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-13 05:55:47.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:48.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:49.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:50.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:51.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:52.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:53.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:54.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:55.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306130555454426000\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:55.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## homo_two_party_continual_input_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        0\n",
      "target    0\n",
      "x0        0\n",
      "x1        0\n",
      "x2        0\n",
      "x3        0\n",
      "x4        0\n",
      "x5        0\n",
      "x6        0\n",
      "x7        0\n",
      "x8        0\n",
      "x9        0\n",
      "x10       0\n",
      "x11       0\n",
      "x12       0\n",
      "x13       0\n",
      "x14       0\n",
      "x15       0\n",
      "x16       0\n",
      "x17       0\n",
      "x18       0\n",
      "x19       0\n",
      "x20       0\n",
      "x21       0\n",
      "x22       0\n",
      "x23       0\n",
      "x24       0\n",
      "x25       0\n",
      "x26       0\n",
      "x27       0\n",
      "x28       0\n",
      "x29       0\n",
      "dtype: int64\n",
      "    id  target        x0        x1        x2        x3        x4        x5  \\\n",
      "0  565       0  1.536720  2.047399  1.421940  1.494959 -0.691230 -0.394820   \n",
      "1  447       1  0.033301 -0.478309 -0.040545 -0.089800 -0.428215 -0.420902   \n",
      "2  488       1 -0.610726 -0.665579 -0.616305 -0.581488  0.886862 -0.677903   \n",
      "3  151       1 -1.486271  0.658341 -1.464904 -1.108862  1.342755  1.124281   \n",
      "4  263       0  0.339783  0.975886  0.257314  0.189884 -1.050685 -0.467976   \n",
      "\n",
      "         x6        x7  ...       x20       x21       x22       x23       x24  \\\n",
      "0  0.236573  0.733827  ...  1.300499  2.260938  1.156857  1.291565 -0.424010   \n",
      "1 -0.317541 -0.480037  ... -0.666881 -1.079087 -0.685152 -0.452951 -0.748357   \n",
      "2 -0.591000 -0.250572  ... -0.122251 -0.114038 -0.154479 -0.280898  0.652367   \n",
      "3  1.275717 -0.545359  ... -0.763969  1.351952 -0.803464 -0.662847  1.796413   \n",
      "4 -0.221590 -0.440448  ... -0.632955 -0.395624 -0.659410 -0.399487 -1.405050   \n",
      "\n",
      "        x25       x26       x27       x28       x29  \n",
      "0 -0.069758  0.252202  0.808431 -0.189161 -0.490556  \n",
      "1 -0.769495 -0.474600 -0.794687  0.241879 -0.689894  \n",
      "2 -0.701869 -0.443764 -0.020461  0.118379 -0.220106  \n",
      "3  1.603016  1.513163 -0.255665  0.308472  3.020373  \n",
      "4 -0.915087 -0.622812 -1.074175 -1.260706 -0.926679  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"breast_homo_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/breast_homo_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:55.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306130555557815430\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:55.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:55:56.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2023-06-13 05:55:57.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-13 05:55:57.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:58.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-13 05:55:59.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:01.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:02.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:03.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:04.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:05.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:09\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:06.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306130555557815430\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:06.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## homo_two_party_hybrid_input_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passengerid     0\n",
      "survived        0\n",
      "pclass          0\n",
      "sex             0\n",
      "age            99\n",
      "sibsp           0\n",
      "parch           0\n",
      "fare            0\n",
      "embarked        1\n",
      "dtype: int64\n",
      "   passengerid  survived  pclass     sex   age  sibsp  parch     fare embarked\n",
      "0          401         1       3    male  39.0      0      0   7.9250        S\n",
      "1          402         0       3    male  26.0      0      0   8.0500        S\n",
      "2          403         0       3  female  21.0      1      0   9.8250        S\n",
      "3          404         0       3    male  28.0      1      0  15.8500        S\n",
      "4          405         0       3  female  20.0      0      0   8.6625        S\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "guest, host = 9999, 10000\n",
    "data_base = \"/data/projects/fate/\"\n",
    "\n",
    "dense_data = {\"name\": \"titanic_homo_host\", \"namespace\": f\"experiment\"}\n",
    "dense_data_dir = os.path.join(data_base, \"persistence/data/titanic_homo_host.csv\")\n",
    "\n",
    "dense_df = pd.read_csv(dense_data_dir)\n",
    "print(dense_df.isna().sum())\n",
    "print(dense_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UPLOADING:||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||100.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:56:06.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202306130556061195500\n",
      "\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:06.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-13 05:56:07.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2023-06-13 05:56:08.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2023-06-13 05:56:08.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:09.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:10.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:11.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:12.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:13.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:14.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component upload_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:15.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202306130556061195500\u001b[0m\n",
      "\u001b[32m2023-06-13 05:56:15.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:00:09\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "pipeline_upload = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest)\n",
    "partition = 4\n",
    "\n",
    "pipeline_upload.add_upload_data(file=dense_data_dir,\n",
    "                                table_name=dense_data[\"name\"],             # table name\n",
    "                                namespace=dense_data[\"namespace\"],         # namespace\n",
    "                                head=1, partition=partition)               # data info\n",
    "pipeline_upload.upload(drop=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad4309918fa4cd1705b305e369b2f64d901b1851e9144aef7b9b07ea3efcb1bb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
